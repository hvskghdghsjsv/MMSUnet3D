model: Generic_UNet_with_bottleneck_PWAM
model_params:
  # these two must be set together
  is_max: False  # disable decoder
  is_max_hungarian: False # turn off hungarian matching

  is_masked_attn: True
  max_dec_layers: 3
  is_max_bottleneck_transformer: True
  vit_depth: 12
  max_msda: ''
  is_max_ms: True # num_feature_levels: 3; default fpn downsampled to os244
  max_ms_idxs: [-4, -3, -2]
  max_hidden_dim: 192
  mw: 1.0
  is_max_ds: True
  is_masking: True
  num_queries: 20
  is_max_cls: True
  is_mhsa_float32: True
  is_vit_pretrain: True
  vit_layer_scale: True

max_loss_cal: 'v1'
disable_ds: False
initial_lr: 0.08
lrschedule: warmup_cosine
resume: 'auto'
warmup_epochs: 10
max_num_epochs: 125 # used 8 cards as default
task: Task001_ATLAS
network: 3d_fullres
network_trainer: nnUNetTrainer
hdfs_base: Atlas_3DTransUNet_encoder_only_p2_bottleneck